import logging
import time
import pandas as pd
import os
import pyodbc
from urllib.parse import quote_plus
from sqlalchemy import create_engine, text, engine
import numpy as np
import math
from typing import Optional

# Suas importa√ß√µes personalizadas
from conexoes import CONEXOES
from consultas_definidas import consultas
from criador_dataframe import CriadorDataFrame

logger = logging.getLogger("logger_financa")


def funcao_conexao(
    nome_conexao: str, tentativas: int = 3, delay_segundos: int = 10
) -> Optional[engine.Engine]:
    """
    Cria uma engine SQLAlchemy com l√≥gica de retry e configura√ß√£o de seguran√ßa.

    Esta fun√ß√£o constr√≥i a string de conex√£o ODBC, incluindo os par√¢metros
    'TrustServerCertificate=yes' e 'Encrypt=yes' para resolver problemas de
    conex√£o SSL com SQL Server.

    Args:
        nome_conexao: Nome da conex√£o definida no arquivo `conexoes.py`.
        tentativas: N√∫mero de tentativas em caso de falha de comunica√ß√£o.
        delay_segundos: Atraso em segundos entre as tentativas.

    Returns:
        Um objeto sqlalchemy.engine.Engine ou None se a conex√£o falhar.
    """
    info = CONEXOES.get(nome_conexao)
    if not info:
        logger.error(f"Conex√£o '{nome_conexao}' n√£o encontrada nas defini√ß√µes.")
        return None

    # Se for OLAP, retorna a string de conex√£o diretamente como antes
    tipo_conexao = info.get("tipo")
    if tipo_conexao == "olap":
        return info.get("str_conexao")
    
    if tipo_conexao != "sql":
        raise ValueError(f"Tipo de conex√£o '{tipo_conexao}' n√£o suportado.")

    # --- Constru√ß√£o da String de Conex√£o ODBC ---
    # Esta parte √© crucial para a corre√ß√£o
    driver = info["driver"].replace('+', ' ')
    servidor = info["servidor"]
    banco = info["banco"]

    # Monta os par√¢metros da string ODBC de forma mais clara
    params = {
        "DRIVER": f"{{{driver}}}",
        "SERVER": servidor,
        "DATABASE": banco,
        "timeout": "600",
        # CORRE√á√ÉO PRINCIPAL: Adiciona os par√¢metros de criptografia e confian√ßa
        "Encrypt": "yes",
        "TrustServerCertificate": "yes"
    }

    if info.get("trusted_connection", False):
        params["Trusted_Connection"] = "yes"
    
    # Converte o dicion√°rio em uma string no formato 'CHAVE=VALOR;CHAVE=VALOR;'
    odbc_str = ";".join(f"{key}={value}" for key, value in params.items())
    
    # Codifica a string para ser usada em uma URL
    string_conexao_url = f"mssql+pyodbc:///?odbc_connect={quote_plus(odbc_str)}"

    # --- L√≥gica de Retry ---
    for tentativa in range(tentativas):
        try:
            engine_instance = create_engine(
                string_conexao_url,
                pool_pre_ping=True,
                pool_recycle=300
            )
            
            # Testa a conex√£o para validar a engine
            with engine_instance.connect():
                logger.info(f"‚úÖ Conex√£o com '{nome_conexao}' estabelecida (pool_recycle=300s).")
                return engine_instance

        except pyodbc.OperationalError as e:
            # Sua l√≥gica de retry para falhas de comunica√ß√£o ('Link de comunica√ß√£o falhou')
            if '08S01' in str(e) and tentativa < tentativas - 1:
                logger.warning(
                    f"‚ö†Ô∏è Falha de comunica√ß√£o ao conectar com '{nome_conexao}'. "
                    f"Tentativa {tentativa + 1}/{tentativas}. "
                    f"Nova tentativa em {delay_segundos}s..."
                )
                time.sleep(delay_segundos)
            else:
                # Se for outro OperationalError (como o de SSL) ou a √∫ltima tentativa
                logger.error(f"Erro final de conex√£o na tentativa {tentativa + 1}.", exc_info=True)
                raise e # Levanta o erro original para an√°lise
        except Exception as e:
            logger.error(f"Erro inesperado ao criar a engine para '{nome_conexao}'.", exc_info=True)
            raise e

    raise ConnectionError(f"N√£o foi poss√≠vel conectar a '{nome_conexao}' ap√≥s {tentativas} tentativas.")


# As fun√ß√µes 'selecionar_consulta_por_nome' e 'salvar_no_financa' est√£o
# muito bem estruturadas e n√£o precisam de altera√ß√µes. A corre√ß√£o na
# 'funcao_conexao' resolver√° o problema que elas enfrentam.



def selecionar_consulta_por_nome(titulo: str) -> pd.DataFrame:
    """Executa a consulta pelo nome e retorna um DataFrame."""
    logger.info(f"‚ñ∂Ô∏è Executando a consulta: '{titulo}'...")
    inicio = time.perf_counter()
    try:
        consulta_encontrada = consultas.get(titulo)
        if not consulta_encontrada:
            raise ValueError(f"Consulta '{titulo}' n√£o encontrada nas defini√ß√µes.")

        tipo_correto = "mdx" if consulta_encontrada.tipo == "olap" else consulta_encontrada.tipo
        
        df = CriadorDataFrame(
            funcao_conexao,
            consulta_encontrada.conexao,
            consulta_encontrada.sql,
            tipo_correto
        ).executar()
        
        fim = time.perf_counter()
        tempo = fim - inicio
        if not df.empty:
            logger.info(f"‚úÖ Consulta '{titulo}' finalizada em {tempo:.2f} segundos ({len(df)} linhas).")
        else:
            logger.warning(f"‚ö†Ô∏è Consulta '{titulo}' finalizada, mas n√£o retornou nenhuma linha.")
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Erro fatal ao executar 'selecionar_consulta_por_nome': {e}", exc_info=True)
        return pd.DataFrame()


def salvar_no_financa(df: pd.DataFrame, table_name: str, retries_per_chunk: int = 3):
    """
    Salva o DataFrame no SQL Server usando duas rodadas de tentativas para blocos.
    Se um bloco falhar na primeira rodada (mesmo ap√≥s retries internos),
    ele √© adicionado a uma lista para uma segunda rodada de tentativas.
    O processo n√£o √© interrompido por falhas individuais de blocos.
    """
    if df.empty:
        logger.warning(f"‚ö†Ô∏è DataFrame est√° vazio. Nada ser√° salvo.")
        return

    logger.info(f"üìÄ Iniciando processo de salvamento para a tabela '{table_name}'.")
    inicio_total = time.perf_counter()
    engine = None
    
    # Lista para guardar os blocos que falharam persistentemente na 1¬™ rodada
    blocos_com_falha_persistente_primeira_rodada = [] 

    try:
        engine = funcao_conexao("SPSVSQL39")
        
        SQL_SERVER_PARAM_LIMIT = 2100
        num_colunas = len(df.columns)
        chunksize = (SQL_SERVER_PARAM_LIMIT // num_colunas) if num_colunas > 0 else 1000
        
        total_rows = len(df)
        num_chunks = math.ceil(total_rows / chunksize)
        
        # --- ETAPA 1: Remover a tabela antiga ---
        with engine.begin() as connection:
            logger.info(f"üóëÔ∏è Removendo a tabela antiga '{table_name}' (se existir)...")
            connection.execute(text(f'DROP TABLE IF EXISTS "{table_name}"'))
            logger.info(f"‚úÖ Tabela removida.")
            
        logger.info(f"üíæ Iniciando 1¬™ RODADA: Salvando {total_rows} linhas em {num_chunks} blocos.")
        chunks = np.array_split(df, num_chunks)

        # --- ETAPA 2: Primeira tentativa de salvamento de todos os blocos ---
        for i, chunk_df in enumerate(chunks):
            bloco_atual = i + 1
            tentativas_chunk_atual = 0
            sucesso_chunk_atual = False
            
            while not sucesso_chunk_atual and tentativas_chunk_atual < retries_per_chunk:
                try:
                    with engine.begin() as connection:
                        if tentativas_chunk_atual > 0:
                             logger.info(f"  -> Retentando bloco {bloco_atual}/{num_chunks} (Tentativa {tentativas_chunk_atual + 1}/{retries_per_chunk} interna)...")
                        else:
                             logger.info(f"  -> Salvando bloco {bloco_atual}/{num_chunks} ({len(chunk_df)} linhas)...")
                        
                        chunk_df.to_sql(name=table_name, con=connection, if_exists='append', index=False, method='multi')
                        sucesso_chunk_atual = True
                
                except pyodbc.OperationalError as e:
                    tentativas_chunk_atual += 1
                    if '08S01' in str(e): # Apenas para falha de comunica√ß√£o
                        logger.warning(f"  ‚ö†Ô∏è Falha de comunica√ß√£o no bloco {bloco_atual}. Tentativa {tentativas_chunk_atual}/{retries_per_chunk}.")
                        if tentativas_chunk_atual < retries_per_chunk:
                            time.sleep(5) # Pequena pausa antes da retentativa interna
                        else:
                            logger.error(f"  ‚ùå Bloco {bloco_atual} falhou ap√≥s {retries_per_chunk} retentativas internas.")
                            # Adiciona √† lista de falhas para a 2¬™ rodada e sai do loop while
                            blocos_com_falha_persistente_primeira_rodada.append((bloco_atual, chunk_df))
                            break 
                    else:
                        # Se for outro erro operacional, re-raise imediatamente
                        logger.error(f"  ‚ùå Erro operacional n√£o recuper√°vel no bloco {bloco_atual}.", exc_info=True)
                        raise e
                except Exception as e: # Captura outros erros inesperados para este chunk
                    logger.error(f"  ‚ùå Erro inesperado ao salvar bloco {bloco_atual}.", exc_info=True)
                    raise e

        # --- ETAPA 3: Segunda rodada (retry) para blocos que falharam persistentemente na 1¬™ ---
        if blocos_com_falha_persistente_primeira_rodada:
            logger.warning(f"--- Iniciando 2¬™ RODADA para {len(blocos_com_falha_persistente_primeira_rodada)} blocos que falharam persistentemente na 1¬™ Rodada ---")
            blocos_com_falha_final = []
            
            for bloco_num, chunk_df_failed in blocos_com_falha_persistente_primeira_rodada:
                try:
                    with engine.begin() as connection:
                        logger.info(f"  -> 2¬™ Rodada: Retentando bloco {bloco_num}...")
                        chunk_df_failed.to_sql(name=table_name, con=connection, if_exists='append', index=False, method='multi')
                    logger.info(f"  ‚úÖ Sucesso na 2¬™ Rodada para o bloco {bloco_num}.")
                except Exception as e:
                    logger.error(f"  ‚ùå FALHA FINAL no bloco {bloco_num} mesmo ap√≥s a 2¬™ Rodada.", exc_info=True)
                    blocos_com_falha_final.append(bloco_num)

            if blocos_com_falha_final:
                # Se ainda houver falhas, levanta uma exce√ß√£o para que a 'main' reporte o status parcial.
                raise RuntimeError(f"N√£o foi poss√≠vel salvar os seguintes blocos mesmo ap√≥s a 2¬™ Rodada: {blocos_com_falha_final}")

        fim_total = time.perf_counter()
        tempo_total = fim_total - inicio_total
        
        if blocos_com_falha_persistente_primeira_rodada and not blocos_com_falha_final:
             logger.info(f"üéâ Sucesso total! Todos os {total_rows} foram salvos, com retentativas na 1¬™ e 2¬™ rodadas, em {tempo_total:.2f} segundos.")
        else:
             logger.info(f"üéâ Sucesso! Todos os {total_rows} foram salvos na 1¬™ Rodada em {tempo_total:.2f} segundos.")

    except Exception as e:
        logger.error(f"‚ùå O processo de salvamento falhou. Causa: {e}", exc_info=True)
        raise e # Re-raise para que a fun√ß√£o main possa capturar e enviar o e-mail de falha.
    finally:
        if engine:
            engine.dispose()

